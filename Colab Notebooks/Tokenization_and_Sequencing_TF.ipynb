{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization_and_Sequencing_TF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDlj899K5b0i"
      },
      "source": [
        "# 1. Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33UTnK1842ij"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3PNoFFI5iEc"
      },
      "source": [
        "# 2. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN_UsjDy5YRl",
        "outputId": "d1c85e11-6371-4a0a-c230-f6d75a35a512"
      },
      "source": [
        "sentences = [\r\n",
        "'Life is so beautiful',\r\n",
        "'Hope keeps us going',\r\n",
        "'Let us celebrate life!'\r\n",
        "]\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\r\n",
        "tokenizer.fit_on_texts(sentences)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "print(word_index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, 'life': 2, 'us': 3, 'is': 4, 'so': 5, 'beautiful': 6, 'hope': 7, 'keeps': 8, 'going': 9, 'let': 10, 'celebrate': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK1DFgV250NW"
      },
      "source": [
        "# 3. Converting text to Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAY7Lkhp5sW0",
        "outputId": "3629b3b6-bca2-472a-f949-76d944637650"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\r\n",
        "\r\n",
        "padded = pad_sequences(sequences, maxlen=5)\r\n",
        "print(\"\\nWord Index = \" , word_index)\r\n",
        "print(\"\\nSequences = \" , sequences)\r\n",
        "print(\"\\nPadded Sequences:\")\r\n",
        "print(padded)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Word Index =  {'<OOV>': 1, 'life': 2, 'us': 3, 'is': 4, 'so': 5, 'beautiful': 6, 'hope': 7, 'keeps': 8, 'going': 9, 'let': 10, 'celebrate': 11}\n",
            "\n",
            "Sequences =  [[2, 4, 5, 6], [7, 8, 3, 9], [10, 3, 11, 2]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 0  2  4  5  6]\n",
            " [ 0  7  8  3  9]\n",
            " [ 0 10  3 11  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vux4pO1p55Z1"
      },
      "source": [
        "# 4. Trying out on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-YQ49r_59hE",
        "outputId": "11e386c2-a17a-4122-89fd-a5a3b2ebc0f9"
      },
      "source": [
        "test_data = [\r\n",
        "'Our life is to celebrate',\r\n",
        "'Hoping for the best!',\r\n",
        "'Let peace prevail everywhere'\r\n",
        "]\r\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\r\n",
        "print(\"\\nTest Sequence = \", test_seq)\r\n",
        "\r\n",
        "padded = pad_sequences(test_seq, maxlen=10, padding='post')\r\n",
        "print(\"\\nPadded Test Sequence: \")\r\n",
        "print(padded)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Sequence =  [[1, 2, 4, 1, 11], [1, 1, 1, 1], [10, 1, 1, 1]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[ 1  2  4  1 11  0  0  0  0  0]\n",
            " [ 1  1  1  1  0  0  0  0  0  0]\n",
            " [10  1  1  1  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}